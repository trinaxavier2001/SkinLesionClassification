{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trinaxavier2001/SkinLesionClassification/blob/main/ResNet50_focalLoss_CrossValidationModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3PwSO7ClcIH",
        "outputId": "4057ac5b-bdd3-4854-cdb1-cfeaee7ad9d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Collecting torch==2.7.0 (from torchvision)\n",
            "  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (4.13.2)\n",
            "Collecting sympy>=1.13.3 (from torch==2.7.0->torchvision)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch==2.7.0->torchvision)\n",
            "  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch==2.7.0->torchvision) (75.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.0->torchvision) (3.0.2)\n",
            "Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/af/eb/ff4b8c503fa1f1796679dce648854d58751982426e4e4b37d6fce49d259c/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m127.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 torchvision-0.22.0 triton-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZY9gZ33lYRn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.model_selection   import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing     import LabelEncoder\n",
        "from sklearn.metrics           import accuracy_score, f1_score\n",
        "from torch.utils.data          import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision               import transforms\n",
        "from torchvision.transforms    import AutoAugment, AutoAugmentPolicy\n",
        "from torchvision.models        import (\n",
        "    resnet50, ResNet50_Weights,\n",
        "    efficientnet_b4, EfficientNet_B4_Weights,\n",
        "    efficientnet_b5, EfficientNet_B5_Weights\n",
        ")\n",
        "from torch.amp                 import autocast, GradScaler\n",
        "from torch.optim               import AdamW\n",
        "from torch.optim.lr_scheduler  import OneCycleLR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFG2jNpwQAQq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjqqnrmHlcKy"
      },
      "outputs": [],
      "source": [
        "# ─── HYPERPARAMETERS ─────────────────────────────────────────────────────────\n",
        "BASE_DIR           = '/content/drive/MyDrive/Skin_Disease_Model'\n",
        "CSV_PATH           = os.path.join(BASE_DIR, 'metadata_with_image_descriptions.csv')\n",
        "BATCH_SIZE         = 32\n",
        "HEAD_WARMUP_EPOCHS = 2\n",
        "STAGE2_EPOCHS      = 18\n",
        "STAGE3_EPOCHS      = 26\n",
        "MAX_LR_HEAD        = 1e-3\n",
        "MAX_LR_STAGE2      = 3e-4\n",
        "MAX_LR_STAGE3      = 5e-5\n",
        "WEIGHT_DECAY       = 1e-2\n",
        "WD_RAMP_EPOCHS     = 15             # slower ramp to full L2\n",
        "GAMMA_FOCAL        = 2.0\n",
        "LABEL_SMOOTHING    = 0.1\n",
        "BETA_TVERSKY       = 0.7\n",
        "ALPHA_TVERSKY      = 0.3\n",
        "TV_GAMMA           = 1.0\n",
        "TV_WEIGHT          = 0.1\n",
        "OVERSAMPLE_RAMP    = (5, 12)        # ramp 1→0.3 between 5–12, hold 0.3 until Stage2 end\n",
        "MIXUP_ALPHA        = 0.4\n",
        "DEVICE             = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "label_encoder      = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN3YFx02KkfC",
        "outputId": "38eb4a19-ebad-4bd0-9781-43c751d4822b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
            "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
            "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
            "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
            "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
            "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
            "\n",
            "        dataset                           gemini_image_description  \\\n",
            "0  vidir_modern  The image shows disease benign keratosis-like ...   \n",
            "1  vidir_modern  The image shows disease benign keratosis-like ...   \n",
            "2  vidir_modern  The image shows disease benign keratosis-like ...   \n",
            "3  vidir_modern  The image shows disease benign keratosis-like ...   \n",
            "4  vidir_modern  The image shows disease benign keratosis-like ...   \n",
            "\n",
            "                                           file_path  label  \n",
            "0  /content/drive/MyDrive/Skin_Disease_Model/HAM1...      2  \n",
            "1  /content/drive/MyDrive/Skin_Disease_Model/HAM1...      2  \n",
            "2  /content/drive/MyDrive/Skin_Disease_Model/HAM1...      2  \n",
            "3  /content/drive/MyDrive/Skin_Disease_Model/HAM1...      2  \n",
            "4  /content/drive/MyDrive/Skin_Disease_Model/HAM1...      2  \n"
          ]
        }
      ],
      "source": [
        "# where to stash resume checkpoints\n",
        "RESUME_DIR = os.path.join(BASE_DIR, \"resumes\")\n",
        "os.makedirs(RESUME_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# ─── DATA & TRANSFORMS ────────────────────────────────────────────────────────\n",
        "all_images = glob.glob(str(Path(BASE_DIR)/\"HAM10000_images_part_*\" / \"*.jpg\"))\n",
        "path_map   = { Path(p).stem: p for p in all_images }\n",
        "\n",
        "class HAM10000Dataset(Dataset):\n",
        "    def __init__(self, df, transform):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tf = transform\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        img = Image.open(row.file_path).convert('RGB')\n",
        "        return self.tf(img), row.label\n",
        "\n",
        "light_tf = transforms.Compose([\n",
        "    transforms.Resize(256), transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],\n",
        "                         [0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "heavy_tf = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
        "    transforms.RandomHorizontalFlip(), transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(0.2,0.2,0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],\n",
        "                         [0.229,0.224,0.225]),\n",
        "    transforms.RandomErasing(p=0.3, scale=(0.02,0.2)),\n",
        "])\n",
        "\n",
        "auto_heavy_tf = transforms.Compose([\n",
        "    AutoAugment(AutoAugmentPolicy.IMAGENET),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
        "    transforms.RandomHorizontalFlip(), transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(0.2,0.2,0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],\n",
        "                         [0.229,0.224,0.225]),\n",
        "    transforms.RandomErasing(p=0.3, scale=(0.02,0.2)),\n",
        "])\n",
        "\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize(256), transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],\n",
        "                         [0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "def preprocess_df(path):\n",
        "    df = pd.read_csv(path)\n",
        "    df['file_path'] = df['image_id'].map(path_map)\n",
        "    df['label']     = label_encoder.fit_transform(df['dx'])\n",
        "    return df\n",
        "print(preprocess_df(CSV_PATH).head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz1uxtK5wwcf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VwAFcEnvkNA"
      },
      "outputs": [],
      "source": [
        "# ─── HYBRID FOCAL‑TVERSKY LOSS ────────────────────────────────────────────────\n",
        "class HybridFocalTverskyLoss(nn.Module):\n",
        "    def __init__(self, alpha, gamma=GAMMA_FOCAL,\n",
        "                 smooth=LABEL_SMOOTHING,\n",
        "                 t_alpha=ALPHA_TVERSKY, t_beta=BETA_TVERSKY,\n",
        "                 t_gamma=TV_GAMMA, t_weight=TV_WEIGHT):\n",
        "        super().__init__()\n",
        "        self.alpha, self.gamma, self.smooth = alpha, gamma, smooth\n",
        "        self.t_a, self.t_b, self.t_g, self.t_w = t_alpha, t_beta, t_gamma, t_weight\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # Focal part\n",
        "        w  = self.alpha.to(logits.device)\n",
        "        ce = F.cross_entropy(\n",
        "            logits, targets,\n",
        "            weight=w,\n",
        "            reduction='none',\n",
        "            label_smoothing=self.smooth\n",
        "        )\n",
        "        p_t   = torch.exp(-ce)\n",
        "        focal = ((1 - p_t)**self.gamma * ce).mean()\n",
        "\n",
        "        # Tversky part\n",
        "        probs   = F.softmax(logits, dim=1)\n",
        "        one_hot = F.one_hot(targets, num_classes=probs.size(1)).float()\n",
        "        TP = (probs * one_hot).sum(0)\n",
        "        FP = (probs * (1 - one_hot)).sum(0)\n",
        "        FN = ((1 - probs) * one_hot).sum(0)\n",
        "        T  = TP / (TP + self.t_a*FP + self.t_b*FN + 1e-6)\n",
        "        tv_loss = ((1 - T)**self.t_g).mean()\n",
        "\n",
        "        return focal + self.t_w * tv_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzi6YOrpOcL1"
      },
      "outputs": [],
      "source": [
        "# ─── ENSEMBLE: ResNet50 + EfficientNet‑B4 + EfficientNet‑B5 ─────────────────\n",
        "class EnsembleModel(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_p=0.5, hidden_dim=512):\n",
        "        super().__init__()\n",
        "        # ResNet50\n",
        "        res    = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "        res_in = res.fc.in_features; res.fc = nn.Identity()\n",
        "        # EfficientNet‑B4\n",
        "        e4     = efficientnet_b4(weights=EfficientNet_B4_Weights.DEFAULT)\n",
        "        e4_in  = e4.classifier[1].in_features; e4.classifier = nn.Identity()\n",
        "        # EfficientNet‑B5\n",
        "        e5     = efficientnet_b5(weights=EfficientNet_B5_Weights.DEFAULT)\n",
        "        e5_in  = e5.classifier[1].in_features; e5.classifier = nn.Identity()\n",
        "\n",
        "        self.backbone_res = res\n",
        "        self.backbone_e4  = e4\n",
        "        self.backbone_e5  = e5\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(res_in + e4_in + e5_in, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        f1 = self.backbone_res(x)\n",
        "        f2 = self.backbone_e4(x)\n",
        "        f3 = self.backbone_e5(x)\n",
        "        return self.head(torch.cat([f1, f2, f3], dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsvbigGWOnoD"
      },
      "outputs": [],
      "source": [
        "# ─── MIXUP ───────────────────────────────────────────────────────────────────\n",
        "def mixup_data(x, y, alpha=MIXUP_ALPHA):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(x.size(0), device=x.device)\n",
        "    return lam*x + (1-lam)*x[idx], y, y[idx], lam\n",
        "\n",
        "\n",
        "# ─── TRAIN / VALIDATE ────────────────────────────────────────────────────────\n",
        "def train_epoch(df_tr, model, crit, optimizer, scheduler, scaler, epoch):\n",
        "    model.train()\n",
        "    preds, labs, tot = [], [], 0.0\n",
        "\n",
        "    # 1) build soft‑oversample ratio\n",
        "    counts   = df_tr.label.value_counts().sort_index()\n",
        "    inv_sqrt = 1.0 / np.sqrt(counts)\n",
        "    e0, e1   = OVERSAMPLE_RAMP\n",
        "    if   epoch <= e0:\n",
        "        ratio = 1.0\n",
        "    elif epoch <= e1:\n",
        "        ratio = 1 - (epoch - e0)/(e1 - e0)\n",
        "    elif epoch <= STAGE2_EPOCHS:\n",
        "        ratio = 0.3           # hold a 30% mix until end of Stage2\n",
        "    else:\n",
        "        ratio = 0.0\n",
        "    samp_wts = df_tr['label'].map(inv_sqrt).values * ratio + (1 - ratio)\n",
        "\n",
        "    # 2) choose augment based on epoch\n",
        "    if   epoch <= HEAD_WARMUP_EPOCHS:\n",
        "        tf = light_tf\n",
        "    elif epoch <= HEAD_WARMUP_EPOCHS + 2:\n",
        "        tf = light_tf         # delay heavy by 2 iters\n",
        "    elif epoch <= (HEAD_WARMUP_EPOCHS + STAGE2_EPOCHS)//2:\n",
        "        tf = heavy_tf\n",
        "    else:\n",
        "        tf = auto_heavy_tf\n",
        "\n",
        "    ds = HAM10000Dataset(df_tr, tf)\n",
        "    loader = (DataLoader(ds, BATCH_SIZE,\n",
        "                         sampler=WeightedRandomSampler(samp_wts,\n",
        "                                                       num_samples=len(samp_wts),\n",
        "                                                       replacement=True),\n",
        "                         num_workers=2, pin_memory=True)\n",
        "              if ratio>0 else\n",
        "              DataLoader(ds, BATCH_SIZE, shuffle=True,\n",
        "                         num_workers=2, pin_memory=True))\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "        # 3) ramp weight‑decay\n",
        "        wd = WEIGHT_DECAY * min(epoch/WD_RAMP_EPOCHS, 1.0)\n",
        "        for pg in optimizer.param_groups:\n",
        "            pg['weight_decay'] = wd\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        if epoch > HEAD_WARMUP_EPOCHS:\n",
        "            x_m, y_a, y_b, lam = mixup_data(x, y)\n",
        "            with autocast(device_type=DEVICE.type):\n",
        "                logits = model(x_m)\n",
        "                loss   = lam*crit(logits, y_a) + (1-lam)*crit(logits, y_b)\n",
        "        else:\n",
        "            with autocast(device_type=DEVICE.type):\n",
        "                logits = model(x)\n",
        "                loss   = crit(logits, y)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        tot  += loss.item() * x.size(0)\n",
        "        p     = logits.argmax(1)\n",
        "        preds.extend(p.cpu().numpy())\n",
        "        labs .extend(y.cpu().numpy())\n",
        "\n",
        "    return tot/len(df_tr), accuracy_score(labs, preds), f1_score(labs, preds, average='macro')\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, loader, crit):\n",
        "    model.eval()\n",
        "    tot, preds, labs = 0.0, [], []\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        with autocast(device_type=DEVICE.type):\n",
        "            logits = model(x)\n",
        "            loss   = crit(logits, y)\n",
        "        tot  += loss.item() * x.size(0)\n",
        "        p     = logits.argmax(1)\n",
        "        preds.extend(p.cpu().numpy())\n",
        "        labs .extend(y.cpu().numpy())\n",
        "\n",
        "    return (tot/len(loader.dataset),\n",
        "            accuracy_score(labs, preds),\n",
        "            f1_score(labs, preds, average='macro'),\n",
        "            preds, labs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM_bA_ozlcQa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ─── CROSS‑VALIDATION LOOP ─────────────────────────────────────────────────\n",
        "def run_cv(df, folds=5, test_size=0.10):\n",
        "    trainval, test = train_test_split(df, test_size=test_size,\n",
        "                                      stratify=df.label, random_state=42)\n",
        "    X, y = trainval.index.values, trainval.label.values\n",
        "    skf  = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
        "\n",
        "    fold_scores = []\n",
        "\n",
        "    for fold, (tr_idx, vl_idx) in enumerate(skf.split(X, y), 1):\n",
        "        print(f\"\\n=== Fold {fold}/{folds} ===\")\n",
        "        df_tr, df_vl = trainval.iloc[tr_idx], trainval.iloc[vl_idx]\n",
        "\n",
        "        vl_loader = DataLoader(HAM10000Dataset(df_vl, val_tf),\n",
        "                               batch_size=BATCH_SIZE,\n",
        "                               shuffle=False, num_workers=2,\n",
        "                               pin_memory=True)\n",
        "\n",
        "        # compute class‑balanced α\n",
        "        counts = df_tr.label.value_counts().sort_index()\n",
        "        beta   = 0.999\n",
        "        cb_wts = (1 - beta) / (1 - beta**counts)\n",
        "        alpha  = torch.tensor((cb_wts/cb_wts.mean()).values,\n",
        "                              dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "        # build model & loss\n",
        "        model = EnsembleModel(num_classes=len(counts)).to(DEVICE)\n",
        "        crit  = HybridFocalTverskyLoss(alpha)\n",
        "        scaler= GradScaler()\n",
        "\n",
        "        # ── Stage1: head‑only warmup ───────────────────────────\n",
        "        head_opt   = AdamW(model.head.parameters(),\n",
        "                           lr=MAX_LR_HEAD, weight_decay=WEIGHT_DECAY/10)\n",
        "        head_sched = OneCycleLR(head_opt,\n",
        "                                max_lr=MAX_LR_HEAD,\n",
        "                                steps_per_epoch=len(df_tr)//BATCH_SIZE+1,\n",
        "                                epochs=HEAD_WARMUP_EPOCHS,\n",
        "                                pct_start=0.3,\n",
        "                                div_factor=10,\n",
        "                                final_div_factor=1e4)\n",
        "\n",
        "        # resume head if checkpoint exists\n",
        "        resume_path  = os.path.join(RESUME_DIR, f\"head_fold{fold}.pth\")\n",
        "        start_epoch1 = 1\n",
        "        if os.path.exists(resume_path):\n",
        "            ck = torch.load(resume_path)\n",
        "            model.load_state_dict(ck['model'])\n",
        "            head_opt.load_state_dict(ck['opt'])\n",
        "            head_sched.load_state_dict(ck['sched'])\n",
        "            start_epoch1 = ck['epoch'] + 1\n",
        "            print(f\" Resuming HEAD fold{fold} at epoch {start_epoch1}\")\n",
        "\n",
        "        best_f1 = 0.0\n",
        "        for ep in range(start_epoch1, HEAD_WARMUP_EPOCHS+1):\n",
        "            # freeze backbone\n",
        "            for net in (model.backbone_res, model.backbone_e4, model.backbone_e5):\n",
        "                for p in net.parameters(): p.requires_grad = False\n",
        "\n",
        "            tr_l, tr_a, tr_f = train_epoch(df_tr, model, crit,\n",
        "                                           head_opt, head_sched, scaler, ep)\n",
        "            vl_l, vl_a, vl_f, _, _ = validate(model, vl_loader, crit)\n",
        "            print(f\"[HEAD] Ep{ep:02d} trF1={tr_f:.3f} vlF1={vl_f:.3f}\")\n",
        "\n",
        "            # save resume\n",
        "            torch.save({\n",
        "                'epoch': ep,\n",
        "                'model': model.state_dict(),\n",
        "                'opt':   head_opt.state_dict(),\n",
        "                'sched': head_sched.state_dict()\n",
        "            }, resume_path)\n",
        "\n",
        "            if vl_f > best_f1:\n",
        "                best_f1 = vl_f\n",
        "                torch.save(model.state_dict(),\n",
        "                           os.path.join(BASE_DIR, f\"best_head_fold{fold}.pth\"))\n",
        "\n",
        "        # ── Stage2: unfreeze + MixUp ──────────────────────────\n",
        "        ckpt = os.path.join(BASE_DIR, f\"best_head_fold{fold}.pth\")\n",
        "        if os.path.exists(ckpt):\n",
        "            model.load_state_dict(torch.load(ckpt))\n",
        "            print(f\" Loaded best head for fold{fold}\")\n",
        "\n",
        "        for net in (model.backbone_res, model.backbone_e4, model.backbone_e5):\n",
        "            for p in net.parameters(): p.requires_grad = True\n",
        "\n",
        "        full_opt   = AdamW(model.parameters(),\n",
        "                           lr=MAX_LR_STAGE2, weight_decay=0.0)\n",
        "        full_sched = OneCycleLR(full_opt,\n",
        "                                max_lr=MAX_LR_STAGE2,\n",
        "                                steps_per_epoch=len(df_tr)//BATCH_SIZE+1,\n",
        "                                epochs=STAGE2_EPOCHS-HEAD_WARMUP_EPOCHS,\n",
        "                                pct_start=0.3,\n",
        "                                div_factor=10,\n",
        "                                final_div_factor=1e4)\n",
        "\n",
        "        no_imp = 0\n",
        "        for ep in range(HEAD_WARMUP_EPOCHS+1, STAGE2_EPOCHS+1):\n",
        "            tr_l, tr_a, tr_f = train_epoch(df_tr, model, crit,\n",
        "                                           full_opt, full_sched, scaler, ep)\n",
        "            vl_l, vl_a, vl_f, preds, labs = validate(model, vl_loader, crit)\n",
        "            print(f\"[ST2] Ep{ep:02d} trF1={tr_f:.3f} vlF1={vl_f:.3f}\")\n",
        "\n",
        "            if vl_f > best_f1:\n",
        "                best_f1 = vl_f\n",
        "                no_imp   = 0\n",
        "                path = os.path.join(BASE_DIR, f\"best_fold{fold}.pth\")\n",
        "                torch.save(model.state_dict(), path)\n",
        "                print(f\"  → New best fold{fold}: {best_f1:.3f}\")\n",
        "            else:\n",
        "                no_imp += 1\n",
        "                if no_imp >= 5:\n",
        "                    print(\" → Early stopping Stage2\")\n",
        "                    break\n",
        "\n",
        "        # ── Stage3: low‑LR fine‑tune ─────────────────────────\n",
        "        fine_opt   = AdamW(model.parameters(),\n",
        "                           lr=MAX_LR_STAGE3, weight_decay=WEIGHT_DECAY)\n",
        "        fine_sched = OneCycleLR(fine_opt,\n",
        "                                max_lr=MAX_LR_STAGE3,\n",
        "                                steps_per_epoch=len(df_tr)//BATCH_SIZE+1,\n",
        "                                epochs=STAGE3_EPOCHS-STAGE2_EPOCHS,\n",
        "                                pct_start=0.3,\n",
        "                                div_factor=10,\n",
        "                                final_div_factor=1e4)\n",
        "\n",
        "        for ep in range(STAGE2_EPOCHS+1, STAGE3_EPOCHS+1):\n",
        "            tr_l, tr_a, tr_f = train_epoch(df_tr, model, crit,\n",
        "                                           fine_opt, fine_sched, scaler, ep)\n",
        "            vl_l, vl_a, vl_f, preds, labs = validate(model, vl_loader, crit)\n",
        "            print(f\"[FT] Ep{ep:02d} tr F1={tr_f:.3f} vl gF1={vl_f:.3f}\")\n",
        "\n",
        "            if vl_f > best_f1:\n",
        "                best_f1 = vl_f\n",
        "                path    = os.path.join(BASE_DIR, f\"best_fold{fold}.pth\")\n",
        "                torch.save(model.state_dict(), path)\n",
        "                print(f\"  → New best fold{fold}: {best_f1:.3f}\")\n",
        "\n",
        "        print(f\">>> Fold {fold} best val‑F1 = {best_f1:.3f}\")\n",
        "        fold_scores.append(best_f1)\n",
        "\n",
        "    print(f\"\\n=== Average CV macro‑F1: {np.mean(fold_scores):.3f} ===\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOCIj_R4lcX-",
        "outputId": "f7f602e3-8742-48ba-ec83-4863787dc1bf"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Fold 1/5 ===\n",
            "[HEAD] Ep01 trF1=0.446 vlF1=0.411\n",
            "[HEAD] Ep02 trF1=0.593 vlF1=0.445\n",
            " Loaded best head for fold1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ST2] Ep03 trF1=0.356 vlF1=0.457\n",
            "  → New best fold1: 0.457\n",
            "[ST2] Ep04 trF1=0.392 vlF1=0.442\n",
            "[ST2] Ep05 trF1=0.357 vlF1=0.561\n",
            "  → New best fold1: 0.561\n",
            "[ST2] Ep06 trF1=0.337 vlF1=0.589\n",
            "  → New best fold1: 0.589\n",
            "[ST2] Ep07 trF1=0.348 vlF1=0.561\n",
            "[ST2] Ep08 trF1=0.374 vlF1=0.594\n",
            "  → New best fold1: 0.594\n",
            "[ST2] Ep09 trF1=0.375 vlF1=0.620\n",
            "  → New best fold1: 0.620\n",
            "[ST2] Ep10 trF1=0.418 vlF1=0.640\n",
            "  → New best fold1: 0.640\n",
            "[ST2] Ep11 trF1=0.324 vlF1=0.584\n",
            "[ST2] Ep12 trF1=0.312 vlF1=0.626\n",
            "[ST2] Ep13 trF1=0.347 vlF1=0.583\n",
            "[ST2] Ep14 trF1=0.356 vlF1=0.632\n",
            "[ST2] Ep15 trF1=0.353 vlF1=0.657\n",
            "  → New best fold1: 0.657\n",
            "[ST2] Ep16 trF1=0.364 vlF1=0.674\n",
            "  → New best fold1: 0.674\n",
            "[ST2] Ep17 trF1=0.377 vlF1=0.681\n",
            "  → New best fold1: 0.681\n",
            "[ST2] Ep18 trF1=0.382 vlF1=0.679\n",
            "[FT] Ep19 trF1=0.404 vlF1=0.680\n",
            "[FT] Ep20 trF1=0.373 vlF1=0.719\n",
            "  → New best fold1: 0.719\n",
            "[FT] Ep21 trF1=0.375 vlF1=0.668\n",
            "[FT] Ep22 trF1=0.385 vlF1=0.708\n",
            "[FT] Ep23 trF1=0.387 vlF1=0.695\n",
            "[FT] Ep24 trF1=0.377 vlF1=0.704\n",
            "[FT] Ep25 trF1=0.414 vlF1=0.707\n",
            "[FT] Ep26 trF1=0.417 vlF1=0.705\n",
            ">>> Fold 1 best val‑F1 = 0.719\n",
            "\n",
            "=== Fold 2/5 ===\n",
            "[HEAD] Ep01 trF1=0.426 vlF1=0.402\n",
            "[HEAD] Ep02 trF1=0.583 vlF1=0.467\n",
            " Loaded best head for fold2\n",
            "[ST2] Ep03 trF1=0.342 vlF1=0.436\n",
            "[ST2] Ep04 trF1=0.349 vlF1=0.446\n",
            "[ST2] Ep05 trF1=0.348 vlF1=0.491\n",
            "  → New best fold2: 0.491\n",
            "[ST2] Ep06 trF1=0.321 vlF1=0.574\n",
            "  → New best fold2: 0.574\n",
            "[ST2] Ep07 trF1=0.376 vlF1=0.624\n",
            "  → New best fold2: 0.624\n",
            "[ST2] Ep08 trF1=0.353 vlF1=0.650\n",
            "  → New best fold2: 0.650\n",
            "[ST2] Ep09 trF1=0.419 vlF1=0.634\n",
            "[ST2] Ep10 trF1=0.407 vlF1=0.602\n",
            "[ST2] Ep11 trF1=0.277 vlF1=0.495\n",
            "[ST2] Ep12 trF1=0.320 vlF1=0.594\n",
            "[ST2] Ep13 trF1=0.339 vlF1=0.613\n",
            " → Early stopping Stage2\n",
            "[FT] Ep19 trF1=0.334 vlF1=0.624\n",
            "[FT] Ep20 trF1=0.322 vlF1=0.654\n",
            "  → New best fold2: 0.654\n",
            "[FT] Ep21 trF1=0.378 vlF1=0.674\n",
            "  → New best fold2: 0.674\n",
            "[FT] Ep22 trF1=0.356 vlF1=0.666\n",
            "[FT] Ep23 trF1=0.381 vlF1=0.657\n",
            "[FT] Ep24 trF1=0.365 vlF1=0.654\n",
            "[FT] Ep25 trF1=0.370 vlF1=0.659\n",
            "[FT] Ep26 trF1=0.385 vlF1=0.667\n",
            ">>> Fold 2 best val‑F1 = 0.674\n",
            "\n",
            "=== Fold 3/5 ===\n",
            "[HEAD] Ep01 trF1=0.422 vlF1=0.389\n",
            "[HEAD] Ep02 trF1=0.605 vlF1=0.480\n",
            " Loaded best head for fold3\n",
            "[ST2] Ep03 trF1=0.390 vlF1=0.424\n",
            "[ST2] Ep04 trF1=0.323 vlF1=0.453\n",
            "[ST2] Ep05 trF1=0.332 vlF1=0.498\n",
            "  → New best fold3: 0.498\n",
            "[ST2] Ep06 trF1=0.358 vlF1=0.594\n",
            "  → New best fold3: 0.594\n",
            "[ST2] Ep07 trF1=0.357 vlF1=0.594\n",
            "[ST2] Ep08 trF1=0.373 vlF1=0.585\n",
            "[ST2] Ep09 trF1=0.393 vlF1=0.617\n",
            "  → New best fold3: 0.617\n",
            "[ST2] Ep10 trF1=0.400 vlF1=0.664\n",
            "  → New best fold3: 0.664\n",
            "[ST2] Ep11 trF1=0.279 vlF1=0.575\n",
            "[ST2] Ep12 trF1=0.323 vlF1=0.597\n",
            "[ST2] Ep13 trF1=0.341 vlF1=0.641\n",
            "[ST2] Ep14 trF1=0.348 vlF1=0.630\n",
            "[ST2] Ep15 trF1=0.382 vlF1=0.660\n",
            " → Early stopping Stage2\n",
            "[FT] Ep19 trF1=0.352 vlF1=0.659\n",
            "[FT] Ep20 trF1=0.355 vlF1=0.648\n",
            "[FT] Ep21 trF1=0.361 vlF1=0.626\n",
            "[FT] Ep22 trF1=0.362 vlF1=0.673\n",
            "  → New best fold3: 0.673\n",
            "[FT] Ep23 trF1=0.383 vlF1=0.659\n",
            "[FT] Ep24 trF1=0.390 vlF1=0.674\n",
            "  → New best fold3: 0.674\n",
            "[FT] Ep25 trF1=0.357 vlF1=0.677\n",
            "  → New best fold3: 0.677\n",
            "[FT] Ep26 trF1=0.380 vlF1=0.671\n",
            ">>> Fold 3 best val‑F1 = 0.677\n",
            "\n",
            "=== Fold 4/5 ===\n",
            "[HEAD] Ep01 trF1=0.427 vlF1=0.416\n",
            "[HEAD] Ep02 trF1=0.598 vlF1=0.493\n",
            " Loaded best head for fold4\n",
            "[ST2] Ep03 trF1=0.375 vlF1=0.453\n",
            "[ST2] Ep04 trF1=0.379 vlF1=0.467\n",
            "[ST2] Ep05 trF1=0.308 vlF1=0.548\n",
            "  → New best fold4: 0.548\n",
            "[ST2] Ep06 trF1=0.328 vlF1=0.608\n",
            "  → New best fold4: 0.608\n",
            "[ST2] Ep07 trF1=0.355 vlF1=0.552\n",
            "[ST2] Ep08 trF1=0.349 vlF1=0.669\n",
            "  → New best fold4: 0.669\n",
            "[ST2] Ep09 trF1=0.378 vlF1=0.674\n",
            "  → New best fold4: 0.674\n",
            "[ST2] Ep10 trF1=0.397 vlF1=0.644\n",
            "[ST2] Ep11 trF1=0.310 vlF1=0.582\n",
            "[ST2] Ep12 trF1=0.341 vlF1=0.639\n",
            "[ST2] Ep13 trF1=0.311 vlF1=0.648\n",
            "[ST2] Ep14 trF1=0.341 vlF1=0.608\n",
            " → Early stopping Stage2\n",
            "[FT] Ep19 trF1=0.349 vlF1=0.657\n",
            "[FT] Ep20 trF1=0.374 vlF1=0.654\n",
            "[FT] Ep21 trF1=0.381 vlF1=0.649\n",
            "[FT] Ep22 trF1=0.368 vlF1=0.655\n",
            "[FT] Ep23 trF1=0.360 vlF1=0.672\n",
            "[FT] Ep24 trF1=0.379 vlF1=0.702\n",
            "  → New best fold4: 0.702\n",
            "[FT] Ep25 trF1=0.361 vlF1=0.697\n",
            "[FT] Ep26 trF1=0.399 vlF1=0.698\n",
            ">>> Fold 4 best val‑F1 = 0.702\n",
            "\n",
            "=== Fold 5/5 ===\n",
            "[HEAD] Ep01 trF1=0.425 vlF1=0.425\n",
            "[HEAD] Ep02 trF1=0.598 vlF1=0.459\n",
            " Loaded best head for fold5\n",
            "[ST2] Ep03 trF1=0.377 vlF1=0.461\n",
            "  → New best fold5: 0.461\n",
            "[ST2] Ep04 trF1=0.383 vlF1=0.499\n",
            "  → New best fold5: 0.499\n",
            "[ST2] Ep05 trF1=0.332 vlF1=0.496\n",
            "[ST2] Ep06 trF1=0.341 vlF1=0.581\n",
            "  → New best fold5: 0.581\n",
            "[ST2] Ep07 trF1=0.365 vlF1=0.617\n",
            "  → New best fold5: 0.617\n",
            "[ST2] Ep08 trF1=0.363 vlF1=0.587\n",
            "[ST2] Ep09 trF1=0.414 vlF1=0.625\n",
            "  → New best fold5: 0.625\n",
            "[ST2] Ep10 trF1=0.403 vlF1=0.721\n",
            "  → New best fold5: 0.721\n",
            "[ST2] Ep11 trF1=0.306 vlF1=0.647\n",
            "[ST2] Ep12 trF1=0.336 vlF1=0.610\n",
            "[ST2] Ep13 trF1=0.317 vlF1=0.634\n",
            "[ST2] Ep14 trF1=0.345 vlF1=0.687\n",
            "[ST2] Ep15 trF1=0.368 vlF1=0.668\n",
            " → Early stopping Stage2\n",
            "[FT] Ep19 trF1=0.378 vlF1=0.667\n",
            "[FT] Ep20 trF1=0.384 vlF1=0.693\n",
            "[FT] Ep21 trF1=0.373 vlF1=0.673\n",
            "[FT] Ep22 trF1=0.361 vlF1=0.709\n",
            "[FT] Ep23 trF1=0.377 vlF1=0.725\n",
            "  → New best fold5: 0.725\n",
            "[FT] Ep24 trF1=0.400 vlF1=0.723\n",
            "[FT] Ep25 trF1=0.414 vlF1=0.727\n",
            "  → New best fold5: 0.727\n",
            "[FT] Ep26 trF1=0.413 vlF1=0.729\n",
            "  → New best fold5: 0.729\n",
            ">>> Fold 5 best val‑F1 = 0.729\n",
            "\n",
            "=== Average CV macro‑F1: 0.700 ===\n"
          ]
        }
      ],
      "source": [
        "if __name__==\"__main__\":\n",
        "    df = preprocess_df(CSV_PATH)\n",
        "    run_cv(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQ16jwK4FKeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a76a13-113a-4b15-bc5f-52fa5a91b223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 0.8473   Macro-F1: 0.7552\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       akiec       0.52      0.91      0.66        33\n",
            "         bcc       0.73      0.96      0.83        51\n",
            "         bkl       0.83      0.67      0.74       110\n",
            "          df       0.67      1.00      0.80        12\n",
            "         mel       0.64      0.70      0.67       111\n",
            "          nv       0.95      0.88      0.92       671\n",
            "        vasc       0.52      0.93      0.67        14\n",
            "\n",
            "    accuracy                           0.85      1002\n",
            "   macro avg       0.69      0.87      0.76      1002\n",
            "weighted avg       0.87      0.85      0.85      1002\n",
            "\n",
            "Sample test predictions:\n",
            "ISIC_0032195: True = nv, Pred = nv\n",
            "ISIC_0033670: True = mel, Pred = nv\n",
            "ISIC_0034181: True = nv, Pred = nv\n",
            "ISIC_0032506: True = nv, Pred = nv\n",
            "ISIC_0026216: True = nv, Pred = nv\n",
            "ISIC_0028580: True = nv, Pred = nv\n",
            "ISIC_0031631: True = nv, Pred = nv\n",
            "ISIC_0025776: True = nv, Pred = nv\n",
            "ISIC_0029311: True = bkl, Pred = akiec\n",
            "ISIC_0025780: True = akiec, Pred = akiec\n"
          ]
        }
      ],
      "source": [
        "# ─── TEST EVALUATION ─────────────────────────────────────────────────────────\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# Load full DataFrame and hold out same test split you used in CV\n",
        "df = preprocess_df(CSV_PATH)\n",
        "_, test_df = train_test_split(df, test_size=0.10, stratify=df.label, random_state=42)\n",
        "\n",
        "# Test DataLoader\n",
        "test_loader = DataLoader(\n",
        "    HAM10000Dataset(test_df, val_tf),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Load each fold's best model and collect for ensemble\n",
        "models = []\n",
        "for fold in range(1, 6):\n",
        "    m = EnsembleModel(num_classes=len(label_encoder.classes_)).to(DEVICE)\n",
        "    ckpt_path = Path(BASE_DIR) / f\"best_fold{fold}.pth\"\n",
        "    m.load_state_dict(torch.load(ckpt_path))\n",
        "    m.eval()\n",
        "    models.append(m)\n",
        "\n",
        "# Run ensemble inference\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        # get softmax from each model\n",
        "        probs = [torch.softmax(m(imgs), dim=1) for m in models]\n",
        "        avg_prob = torch.stack(probs, dim=0).mean(0)\n",
        "        preds = avg_prob.argmax(dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "# Print metrics\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "print(f\"\\nTest Accuracy: {acc:.4f}   Macro-F1: {macro_f1:.4f}\\n\")\n",
        "print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))\n",
        "\n",
        "# Show a few example predictions\n",
        "print(\"Sample test predictions:\")\n",
        "for i in range(10):\n",
        "    img_id = test_df.iloc[i].image_id\n",
        "    true_lbl = label_encoder.inverse_transform([all_labels[i]])[0]\n",
        "    pred_lbl = label_encoder.inverse_transform([all_preds[i]])[0]\n",
        "    print(f\"{img_id}: True = {true_lbl}, Pred = {pred_lbl}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Reconstruct your class names (if you need them):\n",
        "CSV_PATH = '/content/drive/MyDrive/Skin_Disease_Model/metadata_with_image_descriptions.csv'\n",
        "df_meta = pd.read_csv(CSV_PATH)\n",
        "le = LabelEncoder().fit(df_meta['dx'])\n",
        "classes = le.classes_\n",
        "\n",
        "# 2) Compute the confusion matrix\n",
        "#    all_labels = [your true labels array]\n",
        "#    all_preds  = [your predicted labels array]\n",
        "cm = confusion_matrix(all_labels, all_preds, labels=np.arange(len(classes)))\n",
        "\n",
        "# 3) Plot\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "im = ax.imshow(cm,\n",
        "               interpolation='nearest',\n",
        "               cmap='Blues',   # <-- nice light blue palette\n",
        "               vmin=0, vmax=cm.max()*1.0)  # keep full dynamic range\n",
        "\n",
        "# annotate each cell\n",
        "thresh = cm.max() / 2.0\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(j, i, f\"{cm[i, j]:,}\",\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "# labels, title, ticks\n",
        "ax.set(xticks=np.arange(len(classes)),\n",
        "       yticks=np.arange(len(classes)),\n",
        "       xticklabels=classes, yticklabels=classes,\n",
        "       ylabel=\"True label\",\n",
        "       xlabel=\"Predicted label\",\n",
        "       title=\"Confusion Matrix (Frequency)\")\n",
        "\n",
        "# optionally remove the frame on top/right\n",
        "for edge in [\"top\",\"right\"]:\n",
        "    ax.spines[edge].set_visible(False)\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "4TjGZaE8wjGz",
        "outputId": "bfd0a7ee-3b80-4233-ad23-f42a6bcb70b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j4W4LmVry-tN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1gmkmShD-AAKUBP2IssuFBiaAd4nPLuih",
      "authorship_tag": "ABX9TyOKH5YI8ymM0S8SGoyeRByI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}